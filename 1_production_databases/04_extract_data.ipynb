{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres for Data Engineers: Loading and Extracting Data with Tables\n",
    "#### These are exercises done as part of <a href = \"www.dataquest.io\"> DataQuest</a>'s Data Engineer Path\n",
    "This is not replicated for commercial use; strictly personal development.<br>\n",
    "All exercises are (c) DataQuest, with slight modifications so they use my PostGres server on my localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Extracting Data with Tables Mission\n",
    "<b>1.  </b>Instructions:\n",
    "- Use the provided `cur` variable.\n",
    "- Load the `ign.csv` file found in terminal table using the `csv` module.\n",
    "- Run the insert query on the `ign_reviews` table using the execute method using the prepared statement.\n",
    "- Insert every row from the `ign_review.csv` file except for the header row.\n",
    "- Note that the last column is `release_date` instead of the 3 `release_day`, `release_month`, and `release_year` columns.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>We used SQL Alchemy to complete this task in the <a href = \"https://github.com/nmolivo/dataquest_eng/blob/master/1_production_databases/02_opt_tables.ipynb\">second mission</a> of this quest. In the second mission, I also explore populating a database using a csv file. I wound up using `\\COPY`, a psql command. Overall, I appreciate SQL Alchemy the most of all these methods. Nevertheless, I complete all exercises here.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "cur = conn.cursor()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        cur.execute(\"INSERT INTO ign_reviews VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", row)\n",
    "conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.  </b>Instructions:\n",
    "- Use the provided `cur` variable.\n",
    "- Load the `ign.csv` file found in terminal table using the `csv` module.\n",
    "- Create a comma-seperated string of mogrified values using the `mogrify()` method.\n",
    "- Mogrify every row from the `ign_review.csv` file and skip the header row.\n",
    "- Set the comma-seperated string to the variable `mogrified_values`.\n",
    "- Execute the insert query on the `ign_reviews` table using the execute method.\n",
    "- Concat the `mogrified_values` to the `INSERT` statement.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From the previous screen, we discussed how the prepared statement safely converts the Python types to the Postgres types when executing an `INSERT` statement. The conversion takes place in a seperate step within the `psycopg2` library using a method called `mogrify()`\n",
    ">\n",
    ">DataQuest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "cur = conn.cursor()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    mogrified = [cur.mogrify(\"(%s, %s, %s, %s, %s, %s, %s, %s, %s)\", row).decode('utf-8') for row in reader]\n",
    "mogrified_values = \",\".join(mogrified)\n",
    "cur.execute(\"INSERT INTO ign_reviews VALUES \" + mogrified_values)\n",
    "conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `>>> cur.mogrify(\"INSERT INTO test (num, data) VALUES (%s, %s)\", (42, 'bar'))\n",
    "\"INSERT INTO test (num, data) VALUES (42, E'bar')\"`\n",
    ">\n",
    "> <a href = \"http://initd.org/psycopg/docs/cursor.html\">Psycopg2 Cursor Class Documentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.  </b>Instructions:\n",
    "- Use the provided `cur` variable.\n",
    "- Load the `ign.csv` file.\n",
    "- Execute the `COPY ... FROM` method on the `ign_reviews` table using the `copy_expert` method.\n",
    "- Add the `CSV` and `HEADER` options.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `cur.copy_from()` method provides a useful API for file copying but only if the file is defined with a simple seperator (delimiter) character\n",
    ">\n",
    "> To use the `copy_expert()` method, you first have to declare the full `COPY` statement and then pass in the Python file descriptor. The biggest difference you may notice is that we don't copy from a file, but from the `STDIN` which in this case is the Python file object.\n",
    ">\n",
    "> DataQuest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "cur = conn.cursor()\n",
    "with open('ign.csv',  'r') as f:\n",
    "    cur.copy_expert('COPY ign_reviews FROM STDIN WITH CSV HEADER', f)\n",
    "conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4.  </b>Instructions:\n",
    "- Using the time module, play around with the following screen to determine which of the last three methods we introduced is the fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import time\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "cur = conn.cursor()\n",
    "# Multiple single insert statements.\n",
    "start = time.time()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        cur.execute(\n",
    "            \"INSERT INTO ign_reviews VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "            row\n",
    "        )\n",
    "conn.rollback()\n",
    "print(\"Single statment insert: \", time.time() - start)\n",
    "        \n",
    "# Multiple mogrify insert.\n",
    "start = time.time()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    mogrified = [ \n",
    "        cur.mogrify(\"(%s, %s, %s, %s, %s, %s, %s, %s, %s)\", row).decode('utf-8')\n",
    "        for row in reader\n",
    "    ] \n",
    "    mogrified_values = \",\".join(mogrified) \n",
    "    cur.execute('INSERT INTO ign_reviews VALUES ' + mogrified_values)\n",
    "conn.rollback()\n",
    "print(\"Multiple mogrify insert: \", time.time() - start)\n",
    "\n",
    "        \n",
    "# Copy expert method.\n",
    "start = time.time()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    cur.copy_expert('COPY ign_reviews FROM STDIN WITH CSV HEADER', f)\n",
    "conn.rollback()\n",
    "print(\"Copy expert method: \", time.time() - start)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single statment insert:  2.948253631591797<br>\n",
    "Multiple mogrify insert:  1.0108413696289062<br>\n",
    "Copy expert method:  0.16642284393310547<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5.  </b>Instructions:\n",
    "- Use the provided `cur` variable.\n",
    "- Open a `old_ign_reviews.csv` file using the statement with `open()` as `f`.\n",
    "- Execute the `COPY ... TO` method on the `old_ign_reviews` table using the `copy_expert` method.\n",
    "- Add the `CSV` and `HEADER` options.\n",
    "- Write it out to the `old_ign_reviews.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "with open('old_ign_reviews.csv', 'w') as f:\n",
    "    cur.copy_expert('COPY old_ign_reviews TO STDOUT CSV HEADER', f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the previous mission we discussed how to alter an older table and adjust it to incoming new data. However, there are times where we might want to create a new table without altering the older data. With the new table created, we then want to copy all the older data over from the old table and transform it into the new table.\n",
    ">\n",
    ">DataQuest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6.  </b>Instructions:\n",
    "- Use the provided `cur` variable.\n",
    "- Open a `old_ign_reviews.csv` file using the statement with `open()` as `f`.\n",
    "- Execute the `COPY ... TO` method on the `old_ign_reviews` table using the `copy_expert` method.\n",
    "- Add the `CSV` and `HEADER` options.\n",
    "- Process the data and transform it to match the `ign_reviews` table. <font color ='blue'>meaning: made the date columns into one column containing the full date.</font>\n",
    "- Insert the processed rows into the `ign_reviews` table using whatever `INSERT` command you want.\n",
    "- Commit your changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### open()\n",
    ">\n",
    "|Character|Meaning|\n",
    "|------|------|\n",
    "|'r'|open for reading (default)|\n",
    "|'w'|open for writing, truncating the file first|\n",
    "|'x'|open for exclusive creation, failing if the file already exists|\n",
    "|'a'|open for writing, appending to the end of the file if it exists|\n",
    "|'b'|binary mode|\n",
    "|'t'|text mode (default)|\n",
    "|'+'|open a disk file for updating (reading and writing)|\n",
    "|'U'|universal newlines mode (deprecated)|\n",
    ">\n",
    ">The default mode is 'r' (open for reading text, synonym of 'rt'). For binary read-write access, the mode 'w+b' opens and truncates the file to 0 bytes. 'r+b' opens the file without truncation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "cur = conn.cursor()\n",
    "with open('old_ign_reviews.csv', 'r+') as f:\n",
    "    cur.copy_expert('COPY old_ign_reviews TO STDOUT WITH CSV HEADER', f)\n",
    "    f.seek(0)\n",
    "    next(f) #skip header\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        updated_row = row[:8]\n",
    "        updated_row.append(date(int(row[8]), int(row[9]), int(row[10])))\n",
    "        cur.execute(\"INSERT INTO ign_reviews VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", updated_row)\n",
    "    conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Referring to the last method:\n",
    "> This approach is great for tables that contain less than a million rows but as the size of the table increases, it becomes unlikely that this approach would work.\n",
    ">\n",
    "> DataQuest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7.  </b>Instructions:\n",
    "- Use the provided `cur` variable.\n",
    "- Insert rows into the `ign_reviews` table using the `INSERT` with `SELECT` from the `old_ign_reviews` table.\n",
    "- Commit your changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "INSERT INTO ign_reviews (id, score_phrase, title, url, platform, score, genre, editors_choice, release_date)\n",
    "\n",
    "SELECT id, score_phrase, title_of_game_review, url, platform, score, genre, editors_choice, to_date(release_day || '-' || release_month || '-' || release_year, 'DD-MM-YYYY') as release_date \n",
    "\n",
    "FROM old_ign_reviews\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
