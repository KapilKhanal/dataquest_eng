{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Postgres Databases: Vacuuming Postgres Databases\n",
    "#### These are exercises done as part of <a href = \"www.dataquest.io\"> DataQuest</a>'s Data Engineer Path\n",
    "This is not replicated for commercial use; strictly personal development.<br>\n",
    "All exercises are (c) DataQuest, with slight modifications so they use my PostGres server on my localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Shouldn't the speed be the same? Why would query speeds be affected by a few deletes? In this mission, we will learn > the process by which Postgres runs destructive commands, the reason why it can have a non-trivial effect on querying > speeds, and the internal tools to reclaim the lost speed.\n",
    ">\n",
    ">DataQuest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaccuuming Postgres Databases\n",
    "<b>1.</b> Instructions:\n",
    "- Use the provided `cur` object.\n",
    "- Run the `DELETE FROM` command on `homeless_by_coc` to delete all the rows in the table.\n",
    "- Reload the data by running `INSERT` or running a `COPY FROM` psycopg2 cursor query that loads data from the  `homeless_by_coc.csv` file into the `homeless_by_coc` table.\n",
    "    - Commit your changes.\n",
    "- Using `execute()`, count the number of rows from `homeless_by_coc`.\n",
    "- Assign the `int` value return value to `homeless_rows`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "conn = psycopg2.connect(dbname=\"dq\", user=\"hud_admin\", password=\"abc123\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"DELETE FROM homeless_by_coc\")\n",
    "\n",
    "filename = 'homeless_by_coc.csv'\n",
    "with open(filename) as f:\n",
    "    cur.copy_expert('COPY homeless_by_coc FROM STDIN WITH CSV HEADER', f)\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM homeless_by_coc\")\n",
    "homeless_rows = cur.fetchone()[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DELETE`<br>\n",
    "Instead of removing the rows from the table, Postgres will mark the rows as dead, which means they will be eventually removed, once the commit has succeeded.<br>\n",
    "- Dead rows helps keep consistency and isolation within a transaction<br>\n",
    "- Dead rows increase table size and will lengthen query times.\n",
    "- To check if a table has any hanging dead rows, we use an internal table from the `pg_catalog` called `pg_stat_all_tables` which contains a collection of helpful table statistics.<Br><Br>\n",
    "\n",
    "Transactions are a way to ensure multiple users can concurrently run commands.<br>\n",
    "\n",
    "All transactions follow a specific set of properties called ACID.\n",
    "\n",
    "- Atomicity: If one thing fails in the transaction, the whole transaction fails.\n",
    "- Consitency: A transaction will move the database from one valid state to another.\n",
    "- Isolation: Concurrent effects to the database will be followed through as sequential changes.\n",
    "- Durability: Once the transaction is commited, it will stay that way regardless of crash, power outage, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.</b> Instructions\n",
    "- Use the provided `cur` object.\n",
    "- Before the `DELETE` command, find the number of dead rows for the `homeless_by_coc` table.\n",
    "    - Print the result.\n",
    "- After loading the table, find the number of dead rows for the `homeless_by_coc` tables.\n",
    "- Assign the `int` return value to `homeless_dead_rows`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(dbname=\"dq\", user=\"hud_admin\", password=\"abc123\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname = 'homeless_by_coc'\")\n",
    "print(cur.fetchone()[0]) #prints 0\n",
    "\n",
    "cur.execute(\"DELETE FROM homeless_by_coc\")\n",
    "with open('homeless_by_coc.csv') as f:\n",
    "    cur.copy_expert('COPY homeless_by_coc FROM STDIN WITH CSV HEADER', f)\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM homeless_by_coc\")\n",
    "homeless_dead_rows = cur.fetchone()[0] #prints 86529\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>Now to try on the Valenbisi Data. I've deleted and re-made these tables a lot, so I suspect there to be dead rows. However, in the latest version of Postgres, it routinely cleans up unused deadrows for you.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pprint as pp\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"valenbisi2018\", user=\"nmolivo\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname = 'vbstatic'\")\n",
    "print(cur.fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.</b> Instructions:\n",
    "- Use the provided `cur` object.\n",
    "- Note, we have already deleted the rows for you.\n",
    "- Try running a vacuum on `homeless_by_coc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VACUUM`\n",
    "- If you run `VACUUM` without a table name, it will vacuum every user created table the current logged in user has access to\n",
    "- Vacuuming a table will remove the marked dead rows\n",
    "- You have to do this in SQL because the command cannot run in a Transaction Block.\n",
    "- To run `VACUUM` outside a transaction block, we need to explicitly set the autocommit property of the psycopg2.Connection object. \n",
    "    - By setting autocommit to True, you are signalling to the `psycopg2` driver that you do not want your queries to run in a transaction block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. </b>Instructions:\n",
    "- Use the provided `cur` and `conn` objects.\n",
    "- Disable transaction blocks on the connection object.\n",
    "- Find the number of dead rows for the `homeless_by_coc` table.\n",
    "    - Print the result.\n",
    "- Run a vacuum on `homeless_by_coc`.\n",
    "- After vacuuming the table, find the number of dead rows for the `homeless_by_coc` tables.\n",
    "- Assign the int return value to `homeless_dead_rows`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(dbname=\"dq\", user=\"hud_admin\", password=\"abc123\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname='homeless_by_coc'\")\n",
    "print(cur.fetchall()[0])\n",
    "cur.execute(\"VACUUM homeless_by_coc\")\n",
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname='homeless_by_coc'\")\n",
    "homeless_dead_rows = cur.fetchall()[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. </b>Instructions:\n",
    "- Use the provided `cur` and `conn` objects.\n",
    "    - Set the connection to execute outside transaction blocks.\n",
    "- Run an `EXPLAIN` query for a select all query on `homeless_by_coc`.\n",
    "    - Pretty print the results.\n",
    "- Vacuum analyze `homeless_by_coc`.\n",
    "- Rerun the explain query.\n",
    "- Pretty print the results from the explain query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(dbname=\"dq\", user=\"hud_admin\", password=\"abc123\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN SELECT * FROM homeless_by_coc\")\n",
    "pp.pprint(cur.fetchall())\n",
    "\n",
    "cur.execute(\"VACUUM ANALYZE homeless_by_coc\")\n",
    "cur.execute(\"EXPLAIN SELECT * FROM homeless_by_coc\")\n",
    "pp.pprint(cur.fetchall())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[Output]\n",
    "[('Seq Scan on homeless_by_coc  (cost=0.00..2974.24 rows=41024 width=480)',)]\n",
    "[('Seq Scan on homeless_by_coc  (cost=0.00..3429.29 rows=86529 width=88)',)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6.</b> Instructions:\n",
    "- Use the provided `cur` and `conn` objects.\n",
    "- Set the connection to execute outside a transaction block.\n",
    "- Using `cur.execute()`, vacuum full all user created tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most powerful and risky `VACUUM` option: `FULL`\n",
    "- Reclaims space for the entire database server\n",
    "- Claims an <b>exclusive</b> lock on the table it is vacuuming\n",
    "    - This means that no insert, update, or delete queries can be issued against that table during the vacuum duration. \n",
    "    - Select queries on the table are considerably slowed down to the point where they are unusable.\n",
    "- When we described a general `VACUUM`, we stated that it will remove dead rows from the table and reclaim their lost space. However, that disk space is never freed, it is still assigned to the table as extra space to be used when more data is inserted.\n",
    "- `VACUUM FULL` will free the disk space for the whole server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = psycopg2.connect(dbname=\"dq\", user=\"hud_admin\", password=\"abc123\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"VACUUM FULL\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname = \"valenbisi2018\", user = \"nmolivo\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"VACUUM FULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Postgres has a feature called <b>autovacuum</b> and it runs periodically on your tables to ensure that dead rows are removed, and your statistics are up to date.\n",
    ">\n",
    "> In the latest versions of Postgres, autovacuum is on by default, and requires no additional setup.\n",
    ">\n",
    "> When do we explicitly vacuum tables?\n",
    "> 1. Are you running your normal analysis tasks without major table deletes and load? Then, leave vacuuming to the autovacuum.\n",
    ">\n",
    ">2. Have you recently deleted a significant amount of data in your tables, and you want to follow it up with complex analysis commands? Then, run a `VACUUM` or `VACUUM ANALYZE` to ensure optimized query commands.\n",
    ">\n",
    ">3. Are your tables growing out of control, and is there little free space left on the database server? Then, disable all queries and run a `VACUUM FULL` to reclaim a signficant amount of space.\n",
    ">\n",
    ">DataQuest"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
